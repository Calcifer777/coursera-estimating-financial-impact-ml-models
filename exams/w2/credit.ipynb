{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "77e474625a02a3886232cd9bfd174c73",
     "grade": false,
     "grade_id": "cell-e76281053778c41a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Week 2\n",
    "### Model quality and decision making. Benefit curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2c6aca10ff7dea1bbc7d4a335bade074",
     "grade": false,
     "grade_id": "cell-6a9f9b771c232199",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In this jupyter-notebook we will learn how to calculate the profit of using the better model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3173c181ee91f31c958d9608e8c72fd7",
     "grade": false,
     "grade_id": "cell-a76ed6c8a0ea750c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import f1_score as f1\n",
    "\n",
    "import matplotlib.colors\n",
    "\n",
    "\n",
    "sns.set(style=\"white\")\n",
    "\n",
    "np.random.seed(2020)\n",
    "\n",
    "#settings for plots\n",
    "plt.rcParams.update({'font.size': 16,\n",
    "                     'xtick.labelsize' : 14, \n",
    "                     'ytick.labelsize' : 14,\n",
    "                     'axes.labelsize' : 16,\n",
    "                     'axes.titlesize' : 20})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define some functions that will help us to plot graphs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc_auc_plot(model, X_train, y_train,\n",
    "                X_oos, y_oos, X_oot, y_oot, names = ['train', 'oos' ]):\n",
    "    \n",
    "    plt.figure(figsize=(10,8))\n",
    "    colors = ['olivedrab','deepskyblue',  'salmon']\n",
    "    \n",
    "    for it, i in enumerate(names):\n",
    "        \n",
    "        #choose the data\n",
    "        if i == 'train':\n",
    "            X = X_train\n",
    "            y_ = y_train\n",
    "        elif i == 'oos':\n",
    "            X = X_oos\n",
    "            y_ = y_oos\n",
    "        else:\n",
    "            X = X_oot\n",
    "            y_ = y_oot\n",
    "        \n",
    "        y_hat = model.predict_proba(X)[:, 1]\n",
    "        fpr, tpr, _ = roc_curve(y_, y_hat)\n",
    "        gini = 2 * roc_auc_score(y_, y_hat) - 1\n",
    "        plt.plot(fpr, tpr, label = i, color = colors[it], linewidth=2)\n",
    "        print('Model',i, 'gini: ', np.round(gini,6))\n",
    "\n",
    "    plt.xlabel('FPR')\n",
    "    plt.ylabel('TPR')\n",
    "    plt.title('Model old')\n",
    "    plt.legend(bbox_to_anchor=(1, 1));\n",
    "    plt.plot([0,1], [0,1], '--', color='grey', label='Random model')\n",
    "\n",
    "    plt.grid()\n",
    "    _ = plt.legend(loc= 0, prop= {'size': 16})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benefit_plot(model, X_train, y_train,\n",
    "                X_oos, y_oos, X_oot, y_oot, names = ['train', 'oos' ]):\n",
    "                 \n",
    "    plt.figure(figsize=(10,8))\n",
    "\n",
    "    colors = ['olivedrab','deepskyblue',  'salmon']\n",
    "    \n",
    "    max_val = []\n",
    "    for it, i in enumerate(names):\n",
    "        \n",
    "        if i == 'train':\n",
    "            X = X_train\n",
    "            y_ = y_train\n",
    "        elif i == 'oos':\n",
    "            X = X_oos\n",
    "            y_ = y_oos\n",
    "        else:\n",
    "            X = X_oot\n",
    "            y_ = y_oot\n",
    "\n",
    "        benefit = []    \n",
    "        c_acceptance_rate = []\n",
    "        \n",
    "        y_hat = model.predict_proba(X)[:, 1]\n",
    "        \n",
    "        for t in thr:\n",
    "            #calculate confusion matrix\n",
    "            CM = confusion_matrix(y_, (y_hat > t)*1.)  \n",
    "            \n",
    "            #calculate accaptance rate as amount of non-defaulted clients\n",
    "            c_acceptance_rate.append((len(y_hat) - np.sum((y_hat > t)*1.)) / len(y_hat))\n",
    "            TN = CM[0][0]\n",
    "            FN = CM[1][0]\n",
    "            FP = CM[0][1]\n",
    "            \n",
    "            #calculate the financial effect\n",
    "            benefit.append(TN * e_fp - FN * e_fn)\n",
    "\n",
    "        fpr, tpr, _ = roc_curve(y_, y_hat)\n",
    "        print('Model',i, 'Max Benefit: ', np.max(benefit)) \n",
    "        \n",
    "        plt.plot(c_acceptance_rate, benefit, label = i, color = colors[it], linewidth=2)  \n",
    "        plt.plot(c_acceptance_rate[np.argmax(benefit)], np.max(benefit), color = colors[it], marker='*', markersize=10)\n",
    "         \n",
    "\n",
    "    plt.xlabel('Acceptance rate')\n",
    "    plt.ylabel('Benefit')\n",
    "    plt.title('Benefit curve for old model')\n",
    "    plt.legend(bbox_to_anchor=(1, 1));\n",
    "\n",
    "    plt.grid()\n",
    "    _ = plt.legend(loc= 0, prop= {'size': 16})\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ff786879ca165e72afbf2f17db6f1b6b",
     "grade": false,
     "grade_id": "cell-e058f7569d0064ab",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "__Consider a binary classification model $X -> Prob$, e.g. credit scoring__:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2fdb3578b69329103dc9913ccf775f8f",
     "grade": false,
     "grade_id": "cell-444be0af77b6b803",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "666bf43dc07896b6999d909c495080ae",
     "grade": false,
     "grade_id": "cell-5be090b7fb467521",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Load **train**, **out-of-sample** and **out-of-time** samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('../../notebooks/data/w2/benefit-curve/df_train.csv')\n",
    "df_oos = pd.read_csv('../../notebooks/data/w2/benefit-curve//df_oos.csv')\n",
    "df_oot = pd.read_csv('../../notebooks/data/w2/benefit-curve//df_oot.csv')\n",
    "## based on kaggle https://www.kaggle.com/c/GiveMeSomeCredit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8da7524ad419ac5b9dd15ce0e060679c",
     "grade": false,
     "grade_id": "cell-6e5929ff6c8762c1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "__Column description:__\n",
    "\n",
    "- `issue_d` - The month which the loan was funded\n",
    "- `addr_state` - The state provided by the borrower in the loan application\n",
    "- `emp_title` - The job title supplied by the Borrower when applying for the loan.\n",
    "- `installment` - The monthly payment owed by the borrower if the loan originates.\n",
    "- `dti` - A ratio calculated using the borrowerâ€™s total monthly debt payments on the total debt obligations, excluding mortgage and the requested LC loan, divided by the borrowerâ€™s self-reported monthly income.\n",
    "- `funded_amnt` - The total amount committed to that loan at that point in time.\n",
    "- `annual_inc` - The self-reported annual income provided by the borrower during registration.\n",
    "- `emp_length` - Employment length in years. Possible values are between 0 and 10 where 0 means less than one year and 10 means ten or more years. \n",
    "- `term` - The number of payments on the loan. Values are in months and can be either 36 or 60.\n",
    "- `inq_last_6mths` - The number of inquiries in past 6 months (excluding auto and mortgage inquiries)\n",
    "- `mths_since_recent_inq` - Months since most recent inquiry.\n",
    "- `delinq_2yrs` - The number of 30+ days past-due incidences of delinquency in the borrower's credit file for the past 2 years\n",
    "- `chargeoff_within_12_mths` - Number of charge-offs within 12 months\n",
    "- `num_accts_ever_120_pd` - Number of accounts ever 120 or more days past due\n",
    "- `num_tl_90g_dpd_24m` - Number of accounts 90 or more days past due in last 24 months\n",
    "- `acc_open_past_24mths` - Number of trades opened in past 24 months.\n",
    "- `avg_cur_bal` - Average current balance of all accounts\n",
    "- `tot_hi_cred_lim` - Total high credit/credit limit\n",
    "- `delinq_amnt` - The past-due amount owed for the accounts on which the borrower is now delinquent.\n",
    "\n",
    "And all categorical variables are encoded:\n",
    "- `sub_grade` - External assigned loan subgrade\n",
    "- `purpose` - A category provided by the borrower for the loan request.\n",
    "- `home_ownership` - The home ownership status provided by the borrower during registrationÂ or obtained from the credit report.Â Our values are: RENT, OWN, MORTGAGE, OTHER\n",
    "\n",
    "\n",
    "__Target variable:__\n",
    "- `def`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9d782156606785ca4bb0527506bd21b3",
     "grade": false,
     "grade_id": "cell-dd26f6770e097444",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1c119b4264615a73e4aa4b86bc555a66",
     "grade": false,
     "grade_id": "cell-dcac3922d3a5f6c5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "##### *1. Define target*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targ_cols = [i for i in df_train.columns if i != 'def']\n",
    "\n",
    "X_train = df_train[targ_cols]\n",
    "X_oos = df_oos[targ_cols]\n",
    "X_oot = df_oot[targ_cols]\n",
    "\n",
    "y_train = df_train[\"def\"]\n",
    "y_oos = df_oos[\"def\"]\n",
    "y_oot = df_oot[\"def\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "723e830061d62163ca53a0cb26cddd0d",
     "grade": false,
     "grade_id": "cell-a484ffcaacb5412a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "##### *2. Define FP and FN costs*\n",
    "\n",
    "Financial result of model performance depends on FP and FN error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = 900 # amount of loan\n",
    "r = 0.035 # interest rate\n",
    "lgd = 0.25 # losses in case of default\n",
    "e_fp = r * S # 1 type error cost\n",
    "e_fn = lgd * S # 2 type error cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the grid to calculate acceptance rate\n",
    "thr = np.linspace(0,1,41) #41"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "860958391f8745a40e0954cded9dc082",
     "grade": false,
     "grade_id": "cell-6298c59f459cbbce",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "##### 3.*Train old model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_old = LogisticRegression(C=0.02, fit_intercept=True, max_iter=100,\n",
    "          penalty='l1', random_state=123, solver = 'liblinear',\n",
    "          tol=0.01).fit(X_train, y_train)\n",
    "\n",
    "\n",
    "model_old.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "91a84562ff9898ced8e3f81e019b4dc0",
     "grade": false,
     "grade_id": "cell-234f3ea05470aaa5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Plot roc-auc** in order to compare the quality of model on different samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_plot(model_old, X_train, y_train,\n",
    "                X_oos, y_oos, X_oot, y_oot, ['train', 'oos' ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2f9fdf706fc58af4e43535507a7239e1",
     "grade": false,
     "grade_id": "cell-435575f9c556fb1d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We see that the quality of model on oos and oot data is lower than on the train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "dc2cc108743dcd9067e8c96cd3af57dc",
     "grade": false,
     "grade_id": "cell-6f7171ef37b4a4f5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "___\n",
    "**Plot benefit curve** to see the dependence between the benefit and acceptance rate "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "10c1c1a2b28d087e393b4d2dafc08c75",
     "grade": false,
     "grade_id": "cell-6e7a822537d32160",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Simple threshold decision is a level $a$: \n",
    "if $Prob > a$ then some action is undertaken, i.e. $\\hat{ð‘Œ}=1$ and otherwise $\\hat{ð‘Œ}=0$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1e407efe54c4edd71d9bb054d5bf28d1",
     "grade": false,
     "grade_id": "cell-20ee2cc48f555e8e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Acceptance rate** $c$ is a percentage of observations that satisfy rule:\n",
    "$$\n",
    "if Prob \\le a, i.e. c = \\frac{\\sum_{i=1}^{N}I\\{Prob_i\\le a\\}}{N}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "968670ec5897a01bafa0c4fca2fb474e",
     "grade": false,
     "grade_id": "cell-c53270cf6407cad4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We use the function that is defined above. For each acceptance rate we calculate the benefit:\n",
    "1. Pick threshold level a. Calculate c (x axis)\n",
    "2. Calculate FP and FN for given c\n",
    "3. Weigh FP and FN with error costs (e_FP and e_FN) and plot on y axis\n",
    "4. Reiterate 1-3 from $c = 0$ to $c = 1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benefit_plot(model_old, X_train, y_train, X_oos, y_oos, \n",
    "                X_oot, y_oot,['train', 'oos' ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "535a9029cbab872d5e7e0d62bfd47b71",
     "grade": false,
     "grade_id": "cell-a16ccdc4afd762d1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "##### 4.*Train new model*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "68ab4d6aaf2e35ac642c8cb1b2a0a4c2",
     "grade": false,
     "grade_id": "cell-d1bd3b34f0feb7cd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Define better model with optimized hyperparameters (outside this notebook)\n",
    "\n",
    "You can also train your own more complex model (random forest or gradient-boosting models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_new = LogisticRegression(C=2, fit_intercept=True, max_iter=100,\n",
    "          penalty='l1', random_state=123, solver = 'liblinear',\n",
    "          tol=0.01).fit(X_train, y_train)\n",
    "\n",
    "model_new.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1d5c1fe81ede971c5d332df6b923b5ce",
     "grade": false,
     "grade_id": "cell-982373060c5f9215",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Plot roc-auc** in order to compare the quality of model on different samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_plot(model_new, X_train, y_train,X_oos, y_oos, \n",
    "                X_oot, y_oot, ['train', 'oos'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5ce452aa7faf2510acb9c90f7b401e6d",
     "grade": false,
     "grade_id": "cell-247b05fb113c8c12",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Plot benefit curve** to see the dependence between the benefit and acceptance rate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benefit_plot(model_new, X_train, y_train, X_oos, y_oos, \n",
    "                X_oot, y_oot, ['train', 'oos'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "aace0c80373d35372c5caf0518bda704",
     "grade": false,
     "grade_id": "cell-5457671d5cfdbf7b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In our example we get that the higher model quality metrics are, the higher is financial result (in general)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "45788b5ce61dc6536e5e5550a4673376",
     "grade": false,
     "grade_id": "cell-4d9c2742317295d5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bf3a813a353ac45a0dfdcbb3dab16200",
     "grade": false,
     "grade_id": "cell-d33750d7e400600d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "There are some tasks to the examples above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "44b77957715f325b0af25887a01785f0",
     "grade": false,
     "grade_id": "cell-4a56ae67c2e444ee",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Task 1 \n",
    "#### Calculate *gini metrics* for train and oos samples for both models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_train_old = model_old.predict_proba(X_train)[:, 1]\n",
    "y_hat_oos_old = model_old.predict_proba(X_oos)[:, 1]\n",
    "\n",
    "y_hat_train_new = model_new.predict_proba(X_train)[:, 1]\n",
    "y_hat_oos_new = model_new.predict_proba(X_oos)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b9a44ddc8cf929898616e4aa0f3496a5",
     "grade": false,
     "grade_id": "cell-ca4a4672273fc2c4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "train_gini_old_model = 2 * roc_auc_score(y_train, y_hat_train_old) - 1\n",
    "oos_gini_old_model = 2 * roc_auc_score(y_oos, y_hat_oos_old) - 1\n",
    "\n",
    "train_gini_new_model = 2 * roc_auc_score(y_train, y_hat_train_new) - 1\n",
    "oos_gini_new_model = 2 * roc_auc_score(y_oos, y_hat_oos_new) - 1\n",
    "\n",
    "\n",
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"oos_gini_old_model: \", oos_gini_old_model)\n",
    "print(\"train_gini_old_model\", train_gini_old_model)\n",
    "print(\"train_gini_new_model\", train_gini_new_model)\n",
    "print(\"oos_gini_new_model\", oos_gini_new_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "09798e647b84ff49840a3b41125c55ff",
     "grade": true,
     "grade_id": "cell-1b3efb7f56e9fd98",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a79709d535957828749fbefe952260ff",
     "grade": false,
     "grade_id": "cell-d6a70d903835f50a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Task 2 \n",
    "#### Calculate the difference between max benefits for train and oos max for new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "def benefit_calc(model, X_train, y_train,\n",
    "                X_oos, y_oos, X_oot, y_oot, names = ['train', 'oos' ]):\n",
    "                     \n",
    "    \n",
    "    dict_benefit = {}\n",
    "    \n",
    "    max_val = []\n",
    "    for it, i in enumerate(names):\n",
    "          \n",
    "        if i == 'train':\n",
    "            X = X_train\n",
    "            y_ = y_train\n",
    "        elif i == 'oos':\n",
    "            X = X_oos\n",
    "            y_ = y_oos\n",
    "        else:\n",
    "            X = X_oot\n",
    "            y_ = y_oot\n",
    "\n",
    "        benefit = []    \n",
    "        c_acceptance_rate = []\n",
    "        \n",
    "        y_hat = model.predict_proba(X)[:, 1]\n",
    "        \n",
    "        for t in thr:\n",
    "            #calculate confusion matrix\n",
    "            CM = confusion_matrix(y_, (y_hat > t)*1.)  \n",
    "            \n",
    "            #calculate accaptance rate as amount of non-defaulted clients\n",
    "            c_acceptance_rate.append((len(y_hat) - np.sum((y_hat > t)*1.)) / len(y_hat))\n",
    "            TN = CM[0][0]\n",
    "            FN = CM[1][0]\n",
    "            FP = CM[0][1]\n",
    "            \n",
    "            #calculate the financial effect\n",
    "            benefit.append(TN * e_fp - FN * e_fn)\n",
    "          \n",
    "        # YOUR CODE \n",
    "        dict_benefit[i] = pd.DataFrame(columns= ['acc_rate', 'benefit'])\n",
    "        dict_benefit[i]['acc_rate'] = c_acceptance_rate\n",
    "        dict_benefit[i]['benefit'] = benefit\n",
    "        ######\n",
    "    \n",
    "    return dict_benefit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_2 = benefit_calc(model_new, X_train, y_train, X_oos, y_oos, X_oot, y_oot)\n",
    "\n",
    "benefit_train_new_max = d_2['train']['benefit'].max()\n",
    "benefit_oos_new_max = d_2['oos']['benefit'].max()\n",
    "print(\"Max new train benefit {:.5f}\".format(benefit_train_new_max))\n",
    "print(\"Max new OOS benefit {:.5f}\".format(benefit_oos_new_max))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "192af7f18180d849e8311e9859358e91",
     "grade": false,
     "grade_id": "cell-62448106e842a729",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "benefit_diff = benefit_train_new_max - benefit_oos_new_max\n",
    "\n",
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6941d79840b086d57f98e9a7fef7a579",
     "grade": true,
     "grade_id": "cell-43a72eb072e2c43b",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e2f8ade917b1a4f1d125d4f0ce8693a0",
     "grade": false,
     "grade_id": "cell-db88ce394361fb1c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Task 3 \n",
    "__Rewrite the__ `benefit_plot` to `benefit_calc` __function and find__\n",
    "1. benefit that we get for oos sample for the new model at $acceptance\\_rate = 0.62535$\n",
    "2. the difference between the best benefit for oos sample for the new model and benefit from previous item (at $acceptance\\_rate = 0.62535$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d2cf83a3d3f28f10e44c6acd81f2dd4a",
     "grade": false,
     "grade_id": "cell-5483f269c29207fe",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "def benefit_calc(model, X_train, y_train,\n",
    "                X_oos, y_oos, X_oot, y_oot, names = ['train', 'oos' ]):\n",
    "                     \n",
    "    \n",
    "    dict_benefit = {}\n",
    "    \n",
    "    max_val = []\n",
    "    for it, i in enumerate(names):\n",
    "          \n",
    "        if i == 'train':\n",
    "            continue\n",
    "            print(\"skipped\")\n",
    "            X = X_train\n",
    "            y_ = y_train\n",
    "        elif i == 'oos':\n",
    "            X = X_oos\n",
    "            y_ = y_oos\n",
    "        else:\n",
    "            continue\n",
    "            print(\"skipped\")\n",
    "            X = X_oot\n",
    "            y_ = y_oot\n",
    "\n",
    "        benefit = []    \n",
    "        c_acceptance_rate = []\n",
    "        \n",
    "        y_hat = model.predict_proba(X)[:, 1]\n",
    "        \n",
    "        for t in np.linspace(0,1, 1000):\n",
    "            #calculate accaptance rate as amount of non-defaulted clients\n",
    "            c_acceptance_rate.append((len(y_hat) - np.sum((y_hat > t)*1.)) / len(y_hat))\n",
    "            \n",
    "            #calculate confusion matrix\n",
    "            CM = confusion_matrix(y_, (y_hat > t)*1.)\n",
    "            TN = CM[0][0]\n",
    "            FN = CM[1][0]\n",
    "            FP = CM[0][1]\n",
    "            \n",
    "            #calculate the financial effect\n",
    "            benefit.append(TN * e_fp - FN * e_fn)\n",
    "          \n",
    "        # YOUR CODE \n",
    "        dict_benefit[i] = pd.DataFrame(columns= ['acc_rate', 'benefit'])\n",
    "        dict_benefit[i]['acc_rate'] = c_acceptance_rate\n",
    "        dict_benefit[i]['benefit'] = benefit\n",
    "        ######\n",
    "    \n",
    "    return dict_benefit\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = benefit_calc(model_new, X_train, y_train, X_oos, y_oos, X_oot, y_oot)\n",
    "df_oos = d['oos']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "my_data = df_oos.copy()\n",
    "X = my_data[['acc_rate']]\n",
    "X['acc_rate_2'] = X['acc_rate'] ** 2\n",
    "# X['acc_rate_3'] = X['acc_rate'] ** 3\n",
    "y = df_oos['benefit']\n",
    "regression = linear_model.LinearRegression().fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linspace = np.linspace(0, 1, 10000)\n",
    "linspace_data = pd.DataFrame(linspace, columns=['acc_rate'])\n",
    "linspace_data['acc_rate_2'] = linspace_data['acc_rate'] ** 2\n",
    "# linspace_data['acc_rate_3'] = linspace_data['acc_rate'] ** 3\n",
    "y_hats = regression.predict(linspace_data)\n",
    "plt.plot(linspace, y_hats, linewidth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benefit_at_point = regression.predict([[0.62535, 0.62535**2]])[0]\n",
    "diff_benefit = df_oos.benefit.max() - benefit_at_point\n",
    "\n",
    "print(\"Benefit at a=0.62535 -> {:.3f}\".format(benefit_at_point))\n",
    "print(\"Diff benefit -> {:.3f}\".format(diff_benefit))\n",
    "# your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7828a19233b370a613133e63bca88c9c",
     "grade": true,
     "grade_id": "cell-4f4e536e7962efd0",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
