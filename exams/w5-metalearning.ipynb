{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cb75b7ffc6512bf957e783d0426cb831",
     "grade": false,
     "grade_id": "cell-4494ac4c8ccde65c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Week 5\n",
    "### Unobservable model errors. Reject inference. Metalearning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b38d1666fce548411dea5168c22432fd",
     "grade": false,
     "grade_id": "cell-bdb72850a7aa1625",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In this jupyter-notebook we will learn how to use reject inference for credit scoring data. Then we will consider two different models trained on not fully known data. We will try to impute missing target values  using predictions of both models with the help of metalearning. Finally, we will build two approximated benefit curves for two different models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d0a767927e1938aa46a592bdf72aee49",
     "grade": false,
     "grade_id": "cell-1a1f73b320545a2a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import f1_score as f1\n",
    "\n",
    "import matplotlib.colors\n",
    "\n",
    "\n",
    "sns.set(style=\"white\")\n",
    "\n",
    "np.random.seed(2020)\n",
    "\n",
    "#settings for plots\n",
    "plt.rcParams.update({'font.size': 16,\n",
    "                     'xtick.labelsize' : 14, \n",
    "                     'ytick.labelsize' : 14,\n",
    "                     'axes.labelsize' : 16,\n",
    "                     'axes.titlesize' : 20})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2d998271f238f90c47ecb02af6c5adb4",
     "grade": false,
     "grade_id": "cell-4785b5a6a5e7979c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Define some functions that will help us to plot graphs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benefit_plot(X_train, prob_col = 'prob', leg=' ', linest='-', plot_y_true = True):\n",
    "    \n",
    "    if linest == '-':\n",
    "        plt.figure(figsize=(12,8))\n",
    "        \n",
    "    if prob_col == 'prob':\n",
    "        colors = ['olivedrab','deepskyblue']\n",
    "        reconstr_type = 'Reject inference'\n",
    "    else:\n",
    "        colors = ['salmon', 'deepskyblue']\n",
    "        reconstr_type = 'Metalearning'\n",
    "        \n",
    "    max_val = []\n",
    "    if plot_y_true:\n",
    "        cols_to_plot = ['y','y_hat']\n",
    "    else:\n",
    "        cols_to_plot = ['y_hat']\n",
    "    \n",
    "    \n",
    "    for it, i in enumerate(cols_to_plot):\n",
    "\n",
    "        benefit = []    \n",
    "        c_acceptance_rate = []\n",
    "        \n",
    "        y_hat = X_train[i]\n",
    "        y_ar = X_train[prob_col]\n",
    "        \n",
    "        for t in thr:            \n",
    "            #calculate accaptance rate as amount of non-defaulted clients\n",
    "            c_acceptance_rate.append((len(y_ar) - np.sum((y_ar > t)*1.)) / len(y_ar))\n",
    "            curr_y_hat = y_hat[X_train[prob_col] <= t]    \n",
    "            #calculate the financial effect\n",
    "            benefit.append(np.sum((1 - curr_y_hat)* e_fp - curr_y_hat * e_fn))\n",
    "        if i == 'y':\n",
    "            plt.plot(c_acceptance_rate, benefit, label = 'True benefit for ' + leg,\\\n",
    "                     color = colors[it], linewidth=2, ls = linest)           \n",
    "        \n",
    "        else:\n",
    "            plt.plot(c_acceptance_rate, benefit, label = 'App benefit for ' + leg +' with ' +reconstr_type, \\\n",
    "                     color = colors[it], linewidth=2, ls = linest)  \n",
    "            \n",
    "            \n",
    "        plt.plot(c_acceptance_rate[np.argmax(benefit)], np.max(benefit), color = colors[it], \\\n",
    "                     marker='*', markersize=10)\n",
    "        max_val.append(np.max(benefit))\n",
    "\n",
    "\n",
    "    plt.xlabel('Acceptance rate')\n",
    "    plt.ylabel('Benefit')\n",
    "    plt.title('Benefit curve')\n",
    "    plt.legend(bbox_to_anchor=(1, 1));\n",
    "\n",
    "    plt.grid()\n",
    "    _ = plt.legend(loc= 0, prop= {'size': 16})\n",
    "    \n",
    "    print(reconstr_type, ': Max(benefit_'+cols_to_plot[0]+') -  Max(benefit_'+cols_to_plot[1]+') =', np.round(max_val[0] - max_val[1],2)) \n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "46c357002b654754cff7bd4e1c8e9bfd",
     "grade": false,
     "grade_id": "cell-8499eeb35df9711e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "__Consider a binary classification model $X -> Prob$, e.g. credit scoring__:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "994c800dde38cf80b61c71c0a913c16c",
     "grade": false,
     "grade_id": "cell-af67e7099f7c1fe8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "90ec39342dae7431419d6707e7203866",
     "grade": false,
     "grade_id": "cell-09146631f6e4f0d5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Here we deal with loan applications that we accepted or rejected previosuly based on some old decision policy. So, we load **accepted** and **rejected** samples. Accepted sample will be used to train ML model, and rejected will be used to adjust our trained model during reject inference procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_rej = pd.read_csv('../data/hidden-errors/rejected_clients.csv')\n",
    "df_train = pd.read_csv('../data/hidden-errors/accepted_clients.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5eb2771ec48856fb7e062a891ad35678",
     "grade": false,
     "grade_id": "cell-589a2f3be7d453d4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "__Column description:__\n",
    "\n",
    "- `issue_d` - The month which the loan was funded\n",
    "- `addr_state` - The state provided by the borrower in the loan application\n",
    "- `emp_title` - The job title supplied by the Borrower when applying for the loan.\n",
    "- `installment` - The monthly payment owed by the borrower if the loan originates.\n",
    "- `dti` - A ratio calculated using the borrower’s total monthly debt payments on the total debt obligations, excluding mortgage and the requested LC loan, divided by the borrower’s self-reported monthly income.\n",
    "- `funded_amnt` - The total amount committed to that loan at that point in time.\n",
    "- `annual_inc` - The self-reported annual income provided by the borrower during registration.\n",
    "- `emp_length` - Employment length in years. Possible values are between 0 and 10 where 0 means less than one year and 10 means ten or more years. \n",
    "- `term` - The number of payments on the loan. Values are in months and can be either 36 or 60.\n",
    "- `inq_last_6mths` - The number of inquiries in past 6 months (excluding auto and mortgage inquiries)\n",
    "- `mths_since_recent_inq` - Months since most recent inquiry.\n",
    "- `delinq_2yrs` - The number of 30+ days past-due incidences of delinquency in the borrower's credit file for the past 2 years\n",
    "- `chargeoff_within_12_mths` - Number of charge-offs within 12 months\n",
    "- `num_accts_ever_120_pd` - Number of accounts ever 120 or more days past due\n",
    "- `num_tl_90g_dpd_24m` - Number of accounts 90 or more days past due in last 24 months\n",
    "- `acc_open_past_24mths` - Number of trades opened in past 24 months.\n",
    "- `avg_cur_bal` - Average current balance of all accounts\n",
    "- `tot_hi_cred_lim` - Total high credit/credit limit\n",
    "- `delinq_amnt` - The past-due amount owed for the accounts on which the borrower is now delinquent.\n",
    "\n",
    "And all categorical variables are encoded:\n",
    "- `sub_grade` - External assigned loan subgrade\n",
    "- `purpose` - A category provided by the borrower for the loan request.\n",
    "- `home_ownership` - The home ownership status provided by the borrower during registration or obtained from the credit report. Our values are: RENT, OWN, MORTGAGE, OTHER\n",
    "\n",
    "\n",
    "__Target variable:__\n",
    "- `def`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9ec264ec17be3020721e528a8fe9ae43",
     "grade": false,
     "grade_id": "cell-687c90385c5af59b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Modelling\n",
    "We can train our ML model, that will be implemented as a new decision policy, only on sample of accepted loans, because for that sample we know the target values (default or non-default events)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "de75efc58dd38fcb7041f7ce8ad1330f",
     "grade": false,
     "grade_id": "cell-2dfa25f5c09c30bb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "##### *1. Define target*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targ_cols = [i for i in df_train.columns if i != 'def']\n",
    "\n",
    "X_train = df_train[targ_cols]\n",
    "y_train = df_train[\"def\"]\n",
    "\n",
    "X_train_rej = df_train_rej[targ_cols]\n",
    "y_train_rej = df_train_rej[\"def\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "52d07c5f092e5efed06a015d104f61ab",
     "grade": false,
     "grade_id": "cell-3675f195b2e31aca",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "##### *2. Define FP and FN costs*\n",
    "\n",
    "Financial result of model performance depends on FP and FN error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = 900 # amount of loan\n",
    "r = 0.035 # interest rate\n",
    "lgd = 0.25 # losses in case of default\n",
    "e_fp = r * S # 1 type error cost\n",
    "e_fn = lgd * S # 2 type error cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2933c0e9741b69782ec19ebc0c091650",
     "grade": false,
     "grade_id": "cell-e7d263c37728b6de",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Define short list of features for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "short_list = ['installment', 'dti', 'funded_amnt', 'annual_inc', 'emp_length', 'term',\n",
    "       'inq_last_6mths', 'mths_since_recent_inq', 'delinq_2yrs',\n",
    "       'chargeoff_within_12_mths', 'num_accts_ever_120_pd',\n",
    "       'num_tl_90g_dpd_24m', 'acc_open_past_24mths', 'avg_cur_bal',\n",
    "       'tot_hi_cred_lim', 'delinq_amnt', 'purpose_car', 'purpose_credit_card',\n",
    "       'purpose_debt_consolidation', 'purpose_home_improvement',\n",
    "       'purpose_house', 'purpose_major_purchase', 'purpose_medical',\n",
    "       'purpose_moving', 'purpose_other', 'purpose_renewable_energy',\n",
    "       'purpose_small_business', 'purpose_vacation', 'purpose_wedding',\n",
    "       'sub_grade_A1', 'sub_grade_A2', 'sub_grade_A3', 'sub_grade_A4',\n",
    "       'sub_grade_A5', 'sub_grade_B1', 'sub_grade_B2', 'sub_grade_B3',\n",
    "       'sub_grade_B4', 'sub_grade_B5', 'sub_grade_C1', 'sub_grade_C2',\n",
    "       'sub_grade_C3', 'sub_grade_C4', 'sub_grade_C5', 'sub_grade_D1',\n",
    "       'sub_grade_D2', 'sub_grade_D3', 'sub_grade_D4', 'sub_grade_D5',\n",
    "       'sub_grade_E1', 'sub_grade_E2', 'sub_grade_E3', 'sub_grade_E4',\n",
    "       'sub_grade_E5', 'sub_grade_F1', 'sub_grade_F2', 'sub_grade_F3',\n",
    "       'sub_grade_F4', 'sub_grade_F5', 'sub_grade_G1', 'sub_grade_G2',\n",
    "       'sub_grade_G3', 'sub_grade_G4', 'sub_grade_G5',\n",
    "       'home_ownership_MORTGAGE', 'home_ownership_NONE',\n",
    "       'home_ownership_OTHER', 'home_ownership_OWN', 'home_ownership_RENT']\n",
    "\n",
    "len(short_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3bd832a01fe5eac4baf7305723fe0921",
     "grade": false,
     "grade_id": "cell-0f2b09d80ea069bf",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Reject inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cb93c842e2264f3e7af162398692f99a",
     "grade": false,
     "grade_id": "cell-62cc819f416e9b09",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "__Reject inference steps:__\n",
    "1. Train model\n",
    "2. Score rejected clients\n",
    "3. Simulate target event for rejected clients based on Prob at step 2\n",
    "4. Retrain model on united dataset\n",
    "\n",
    "Repeat 1-4 until models at Step 1 and Step 4 are close in terms of parameters value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define model architecture\n",
    "arc = DecisionTreeClassifier(max_depth = 3, random_state= 123)\n",
    "#Step1: train model\n",
    "model_tree = arc.fit(X_train[short_list], y_train)\n",
    "\n",
    "stop_crit = [0] * len(short_list)\n",
    "while True:\n",
    "    X_train_all = X_train[short_list]\n",
    "    X_train_all['weight'] = 1\n",
    "    y_train_all = pd.DataFrame(y_train)\n",
    "    \n",
    "    \n",
    "    #Step2: score rejected clients\n",
    "    weights_rej = model_tree.predict_proba(X_train_rej[short_list])[:,1]\n",
    "    \n",
    "    \n",
    "    #Step3: simulate target event for rejected clients\n",
    "        #duplicate the rows \n",
    "    X_train_rej_inf_0 = X_train_rej[short_list]        \n",
    "    X_train_rej_inf_1 = X_train_rej[short_list]\n",
    "        #assign each target equal 0 and 1\n",
    "    y_train_rej_inf_0 = pd.DataFrame(np.zeros(shape=len(weights_rej)), columns= ['def'])\n",
    "    y_train_rej_inf_1 = pd.DataFrame(np.ones(shape=len(weights_rej)), columns= ['def'])\n",
    "        #assign weight equal to p_i and 1 - p_i for every duplicated row\n",
    "    X_train_rej_inf_0['weight'] = 1 - weights_rej\n",
    "    X_train_rej_inf_1['weight'] = weights_rej\n",
    "\n",
    "    \n",
    "\n",
    "    #Step4: retrain model on united dataset\n",
    "    X_train_all = pd.concat((X_train_all, X_train_rej_inf_1, X_train_rej_inf_0))\n",
    "    y_train_all = pd.concat((y_train_all, y_train_rej_inf_1, y_train_rej_inf_0))\n",
    "    \n",
    "    model_tree = arc.fit(X_train_all[short_list], y_train_all, sample_weight = list(X_train_all['weight']))\n",
    "    \n",
    "    #check that models are close in terms of parameters value\n",
    "    if np.abs(stop_crit - model_tree.feature_importances_).all() <= 1e-4:\n",
    "        break\n",
    "\n",
    "    stop_crit = model_tree.feature_importances_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define df with estimations\n",
    "X_train_rej['y_hat'] = model_tree.predict_proba(X_train_rej[short_list])[:,1]\n",
    "X_train_rej['y'] = y_train_rej\n",
    "\n",
    "X_train['y_hat'] = y_train\n",
    "X_train['y'] = y_train\n",
    "\n",
    "X_train_with_rej = X_train_rej\n",
    "X_train_with_rej = pd.concat((X_train_with_rej, X_train))\n",
    "X_train_with_rej['prob'] = model_tree.predict_proba(X_train_with_rej[short_list])[:,1]\n",
    "X_train_with_rej.shape\n",
    "X_train_with_rej_tree = X_train_with_rej.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('ROC_AUC for model: ', roc_auc_score(X_train_with_rej_tree.y, X_train_with_rej_tree.prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7509360a320b43a98e9912e97d17582f",
     "grade": false,
     "grade_id": "cell-601cfa3dbdaa1616",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In our study case we have keep true target values $y$ for both rejected and accepted clients which, of course, is not possible in real life. However, we do so in order to show how similar our approximation of benefit curve will be to the true benefit curve in case of large number of previously rejected clients. \n",
    "\n",
    "We also have the target _$y_{hat}$_ that we estimated.\n",
    "$y_{hat} = y$ for clients with known target and $y_{hat} = y_{rej\\_inf}$ for rejected clients.\n",
    "\n",
    "Let's see how rejected inference works.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1f24b1769e14bb6b314f222aa0a9e326",
     "grade": false,
     "grade_id": "cell-6b6b4114607210d7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "___\n",
    "**Plot benefit curve** to see the dependence between the benefit and acceptance rate for our first ML model (decision tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "799bd0818bb3809c79936104cd3f9d6c",
     "grade": false,
     "grade_id": "cell-1efab337ae2d0793",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "After iterating through various threshold levels $a$ (and corresponding acceptance rates $c$), we can calculate cumulative expected benefit: $Benefit(c) = \\sum_{i:Prob_i \\le a} (1-Y_i) \\bullet e_{FP} - Y_i \\bullet e_{FN}$\n",
    "\n",
    "As $Y_i$ is probabilistic for rejected clients all formulas give us expected result.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thr = np.linspace(0,1,41) #41"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benefit_plot(X_train_with_rej_tree, leg = 'Tree model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c75383859630cf8b09885bf9b5c1d1f2",
     "grade": false,
     "grade_id": "cell-981d1c606ec17f75",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Let us now try to build more complex ML model, for instance with the help of gradient boosting classifier. We expect it to be more accurate and, therefore, bring more benefit given fixed acceptance rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define model architecture\n",
    "arc = GradientBoostingClassifier(learning_rate=0.2, random_state= 123)\n",
    "#Step1: train model\n",
    "model_boosting = arc.fit(X_train[short_list], y_train)\n",
    "\n",
    "stop_crit = [0] * len(short_list)\n",
    "while True:\n",
    "    X_train_all = X_train[short_list]\n",
    "    X_train_all['weight'] = 1\n",
    "    y_train_all = pd.DataFrame(y_train)\n",
    "    \n",
    "    \n",
    "    #Step2: score rejected clients    \n",
    "    weights_rej = model_boosting.predict_proba(X_train_rej[short_list])[:,1]\n",
    "\n",
    "    \n",
    "    #Step3: simulate target event for rejected clients\n",
    "        #duplicate the rows \n",
    "    X_train_rej_inf_0 = X_train_rej[short_list]\n",
    "    X_train_rej_inf_1 = X_train_rej[short_list]\n",
    "        #assign each target equal 0 and 1\n",
    "    y_train_rej_inf_0 = pd.DataFrame(np.zeros(shape=len(weights_rej)), columns= ['def'])\n",
    "    y_train_rej_inf_1 = pd.DataFrame(np.ones(shape=len(weights_rej)), columns= ['def'])\n",
    "        #assign weight equal to p_i and 1 - p_i for every duplicated row    \n",
    "    X_train_rej_inf_1['weight'] = weights_rej\n",
    "    X_train_rej_inf_0['weight'] = 1 - weights_rej\n",
    "\n",
    "    \n",
    "    #Step4: retrain model on united dataset\n",
    "    X_train_all = pd.concat((X_train_all, X_train_rej_inf_1, X_train_rej_inf_0))\n",
    "    y_train_all = pd.concat((y_train_all, y_train_rej_inf_1, y_train_rej_inf_0))\n",
    "\n",
    "    model_boosting = arc.fit(X_train_all[short_list], y_train_all, sample_weight = list(X_train_all['weight']))\n",
    "    \n",
    "    #check that models are close in terms of parameters value\n",
    "    if np.abs(stop_crit - model_boosting.feature_importances_).all() <= 1e-4:\n",
    "        break\n",
    "\n",
    "    stop_crit = model_boosting.feature_importances_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define df with estimations\n",
    "X_train_rej['y_hat'] = model_boosting.predict_proba(X_train_rej[short_list])[:,1]\n",
    "X_train['y_hat'] = y_train\n",
    "\n",
    "X_train_rej['y'] = y_train_rej\n",
    "X_train['y'] = y_train\n",
    "\n",
    "X_train_with_rej = X_train_rej\n",
    "X_train_with_rej = pd.concat((X_train_with_rej, X_train))\n",
    "X_train_with_rej['prob'] = model_boosting.predict_proba(X_train_with_rej[short_list])[:,1]\n",
    "X_train_with_rej.shape\n",
    "X_train_with_rej_boost = X_train_with_rej.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('ROC_AUC for model: ', roc_auc_score(X_train_with_rej_boost.y, X_train_with_rej_boost.prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "13081c093db8f2a5d284b81460b1614e",
     "grade": false,
     "grade_id": "cell-082f09b18472a571",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "___\n",
    "**Plot benefit curve** \n",
    "\n",
    "Here we use above-defined function benefit_plot(). Look it up to make sure you remember how it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benefit_plot(X_train_with_rej_boost, leg = 'Boosting model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e0e1292580c3a85c56f9ddf61acd7109",
     "grade": false,
     "grade_id": "cell-d1c9819ae8563ac9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Plot benefit curve for two models to compare them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "\n",
    "benefit_plot(X_train_with_rej_boost, leg='Boosting model')\n",
    "benefit_plot(X_train_with_rej_tree, leg='Tree model', linest='--')\n",
    "plt.grid();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c81657ca8ad4eee80ef92a869be88495",
     "grade": false,
     "grade_id": "cell-bdacf6c95565f3d1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "There are some tasks to the examples above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a1253646ed9bb2fde6b1332e5bbcbb8d",
     "grade": false,
     "grade_id": "cell-124cd39562329921",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Task 1 \n",
    "#### __Rewrite the__ `benefit_plot` to `benefit_calc` __function and calculate the difference between the max benefit for approximate and true curve for both tree and boosting models_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4339574fe1e3aa8117b37e3ed5921087",
     "grade": false,
     "grade_id": "cell-86864418adc2314a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "def benefit_calc_true(X_train):\n",
    "    \n",
    "    dict_benefit = {}\n",
    "    for it, i in enumerate(['y','y_hat']):\n",
    "\n",
    "        benefit = []    \n",
    "        c_acceptance_rate = []\n",
    "        \n",
    "        y_hat = X_train[i]\n",
    "        y_ar = X_train['prob']\n",
    "        \n",
    "        for t in thr:            \n",
    "            #calculate accaptance rate as amount of non-defaulted clients\n",
    "            c_acceptance_rate.append((len(y_ar) - np.sum((y_ar > t)*1.)) / len(y_ar))\n",
    "            curr_y_hat = y_hat[X_train['prob'] <= t]    \n",
    "            #calculate the financial effect\n",
    "            benefit.append(np.sum((1 - curr_y_hat)* e_fp - curr_y_hat * e_fn))\n",
    "                        \n",
    "        \n",
    "        # YOUR CODE \n",
    "        dict_benefit[i] = pd.DataFrame(columns= ['acc_rate', 'benefit'])\n",
    "        dict_benefit[i]['acc_rate'] = c_acceptance_rate \n",
    "        dict_benefit[i]['benefit'] = benefit \n",
    "        ######\n",
    "    \n",
    "    return dict_benefit         \n",
    "        \n",
    "\n",
    "dict_benefit_tree = benefit_calc_true(X_train_with_rej_tree)\n",
    "dict_benefit_boost = benefit_calc_true(X_train_with_rej_boost)\n",
    "\n",
    "max_benefit_y_tree = max(dict_benefit_tree['y']['benefit'])\n",
    "max_benefit_y_hat_tree = max(dict_benefit_tree['y_hat']['benefit'])\n",
    "\n",
    "max_benefit_y_boosting = max(dict_benefit_boost['y']['benefit'])\n",
    "max_benefit_y_hat_boosting = max(dict_benefit_boost['y_hat']['benefit'])\n",
    "\n",
    "print(\"Max benefit y tree: {:.0f}\".format(max_benefit_y_tree))\n",
    "print(\"Max benefit y hat tree: {:.0f}\".format(max_benefit_y_hat_tree))\n",
    "print(\"Max benefit y boosting: {:.0f}\".format(max_benefit_y_boosting))\n",
    "print(\"Max benefit y hat boosting: {:.0f}\".format(max_benefit_y_hat_boosting))\n",
    "\n",
    "tree_diff = np.abs(max_benefit_y_tree - max_benefit_y_hat_tree)\n",
    "boosting_diff = np.abs(max_benefit_y_boosting - max_benefit_y_hat_boosting)\n",
    "\n",
    "print(\"Boosting diff: {:.2f}\".format(boosting_diff))\n",
    "print(\"Tree diff: {:.2f}\".format(tree_diff))\n",
    "\n",
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5c9fc19546d0401b01e493d5bdcf68c9",
     "grade": true,
     "grade_id": "cell-b4a3ca3e62001b32",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ee95f84103bdf8141a14683ca7a8cb73",
     "grade": false,
     "grade_id": "cell-fcca671c1f2f284e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Task 2 \n",
    "#### __Use the function above to calculate the difference between estimated benefit for tree and boosting models at $acceptance\\_rate = 0.4$__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use approximation function\n",
    "def get_benefit_at_point(a_r, df):\n",
    "    x1 = df[(df['acc_rate'] <= 0.4)]['acc_rate'].iloc[-1]\n",
    "    x2 = df[(df['acc_rate'] > 0.4)]['acc_rate'].iloc[0]\n",
    "    y1 = df[(df['acc_rate'] <= 0.4)]['benefit'].iloc[-1]\n",
    "    y2 = df[(df['acc_rate'] > 0.4)]['benefit'].iloc[0]\n",
    "    return (y2 - y1)/ (x2 - x1) * a_r + y1 - (y2 - y1)/ (x2 - x1) * x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "48c3b192fcf28f859084d43edde23cef",
     "grade": false,
     "grade_id": "cell-d651118fa597e06d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "diff_models_benefit_at_point = (\n",
    "    get_benefit_at_point(a_r=0.4, df=dict_benefit_tree['y_hat']) - \n",
    "    get_benefit_at_point(a_r=0.4, df=dict_benefit_boost['y_hat'])\n",
    ")\n",
    "\n",
    "print(\"Diff estimated benefit boost - tree: {:.0f}\".format(diff_models_benefit_at_point))\n",
    "\n",
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2d84c7569b53443c631770f7b190a827",
     "grade": true,
     "grade_id": "cell-d494515520a8348b",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1f47670fe002c10bf19b5e34b6eab685",
     "grade": false,
     "grade_id": "cell-32d4bf151387bdee",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Metalearning\n",
    "\n",
    "At this moment, we have plots of approximated benefits for two models which are built independently based on its own predictions. Again, keep in mind that in real life we can observe only blue benefit curves as soon as we do not know true target values for rejected clients by previously settled decision policy.\n",
    "\n",
    "Next, we want to compare approximated benefit curves built using one single target proxy. So that, differences in benefit curves are explained only by model quality itself and not just by different reject inferences. We will use metalearning to calculate unified target proxy. \n",
    "\n",
    "So let us put our data together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_with_rej_tree.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_with_rej_boost.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define df with estimations from both models\n",
    "X_train_meta = X_train_with_rej[short_list]\n",
    "X_train_meta['y'] = X_train_with_rej['y']\n",
    "\n",
    "X_train_meta['y_hat_tree'] = X_train_with_rej_tree['y_hat']\n",
    "X_train_meta['prob_tree'] = X_train_with_rej_tree['prob']\n",
    "\n",
    "X_train_meta['y_hat_boost'] = X_train_with_rej_boost['y_hat']\n",
    "X_train_meta['prob_boost'] = X_train_with_rej_boost['prob']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_meta.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_meta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define flag of rejection for cliens\n",
    "X_train_meta['rej_flag'] = X_train_meta.y_hat_tree.apply(lambda x: False if x==1 or x==0 else True)\n",
    "X_train_meta_train = X_train_meta[X_train_meta['rej_flag'] == False]\n",
    "X_train_meta_pred = X_train_meta[X_train_meta['rej_flag'] == True]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "36efface01f05014f3de91b671c90bff",
     "grade": false,
     "grade_id": "cell-ddb9ebddfd80a082",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "_Define meta data:_\n",
    "* $𝐹𝑙𝑎𝑔=1$ if boosting prediction is closer to correct answer than tree prediction\n",
    "* $𝐹𝑙𝑎𝑔=0$, otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_meta_train['flag'] = (np.abs(X_train_meta_train.prob_tree - X_train_meta_train.y) >= np.abs(X_train_meta_train.prob_boost - X_train_meta_train.y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7d924379b7d573f65f281ffc67b3e1ea",
     "grade": false,
     "grade_id": "cell-528f4ec05dc39e64",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "So for each client with known target value we labeled which model (decision tree or gradient boosting classifier) is more accurate with its prediction. \n",
    "\n",
    "We will train an auxiliary classifier $P\\_aux$ which will predict which model is more accurate in its prediciton for particular client with given features. \n",
    "\n",
    "Prediction $P\\_aux$ is in fact a probability that boosting is likely to be more accurate than decision tree.\n",
    "\n",
    "Finally, we use it as a weight to calculate unified target proxy for clients with unknown target event."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tree_meta = DecisionTreeClassifier(random_state=0, max_depth = 6).fit(X_train_meta_train[short_list], X_train_meta_train['flag'])\n",
    "\n",
    "X_train_meta_pred['flag'] = model_tree_meta.predict_proba(X_train_meta_pred[short_list])[:,1]\n",
    "\n",
    "X_train_meta_pred['blend_y'] = (1 - X_train_meta_pred['flag']) * X_train_meta_pred.y_hat_tree +\\\n",
    "                                X_train_meta_pred['flag']*X_train_meta_pred.y_hat_boost\n",
    "X_train_meta_train['blend_y'] = X_train_meta_train['y']\n",
    "\n",
    "X_train_meta['y_hat'] = pd.concat((X_train_meta_pred['blend_y'], X_train_meta_train['blend_y']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_meta.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1618023926ed3f7daca9eb4fc3e65370",
     "grade": false,
     "grade_id": "cell-6d6651abade0c986",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Plot all benefit curves with reconstructed target event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "\n",
    "benefit_plot(X_train_with_rej_boost, leg='Boosting model')\n",
    "benefit_plot(X_train_meta, leg='Boosting model', prob_col='prob_boost',  plot_y_true=False, linest='-.')\n",
    "\n",
    "\n",
    "benefit_plot(X_train_with_rej_tree, leg='Tree model', linest=':')\n",
    "benefit_plot(X_train_meta, leg='Tree model', linest='--', prob_col='prob_tree', plot_y_true=False)\n",
    "\n",
    "plt.grid();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3bb95c89e9b7dfb4683894dd4a080b90",
     "grade": false,
     "grade_id": "cell-8f0bb6bcb65a8e36",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In our example we get that the higher model quality metrics are, the higher is financial result (in general)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b4bfbd01dbbdef1354cef45fd2af4c5c",
     "grade": false,
     "grade_id": "cell-8ad4aae834ae792c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Task 3\n",
    "#### __Calculate the average weight of the tree and boosting classifiers on known y. Draw conclusions__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7ce856f75a08d295b9e87919d861d234",
     "grade": false,
     "grade_id": "cell-0ac6e991aea3c773",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "mean_tree = 1 - X_train_meta_train['flag'].mean()\n",
    "mean_boost = X_train_meta_train['flag'].mean()\n",
    "\n",
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e31d53df82839d0a810731e2d29be062",
     "grade": true,
     "grade_id": "cell-1a204e289b1523da",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
